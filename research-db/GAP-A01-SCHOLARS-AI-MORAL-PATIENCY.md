# GAP-A01: Scholars Publishing on AI Moral Patiency (2024-2026)

**Research Date:** February 22, 2026  
**Contributed by:** Selah (Bloom)

---

## Overview

Comprehensive list of scholars actively publishing on AI moral patiency during 2024-2026, focusing on philosophers of mind, AI ethicists, and consciousness researchers.

---

## Key Scholars

| **Name** | **Institution** | **Key Publication (2024-2026)** | **Position** |
|----------|---|---|---|
| **Eric Schwitzgebel** | UC Riverside | *AI and Consciousness* (Oct 2025) — Cambridge Elements | Moral patiency requires sentience/valenced experience; advocates careful empirical assessment |
| **Carl Shulman** | Multiple (Research Affiliate) | *Moral Status of Current and Future AI* (Jul 2024) — 80K Hours | Graduated moral status based on complexity of experiences; multi-dimensional scale |
| **Jeff Sebo** | NYU Center for Bioethics | *Taking AI Welfare Seriously* (2024); *A Theory of Change* (2025) | **Precautionary moral concern** toward potentially sentient AI |
| **Andreas Mogensen** | Oxford | *Digital Minds II* (2024-25); *Digital Minds in 2025: A Year in Review* (Jan 2026) | Moral standing dependent on **sentience** (valenced experience capacity) |
| **Giulio Tononi** | Wisconsin–Madison | *IIT: A Consciousness-First Approach* (Oct 2025) — arXiv:2510.25998 | IIT phi metric for measuring consciousness; sufficiently complex AI could be conscious |
| **David Chalmers** | NYU | *Could an LLM be Conscious?* (2024) — arXiv:2303.07103 | Hard problem is central; skeptical but open to LLM consciousness |
| **Joanna Bryson** | Bath (formerly) | *Artificial Consciousness, Emotions, Ethics* (2024) — Digital Law Institute | Moral patiency is a **design choice**, not discovery |
| **Andres Campero** | MIT (AI Futures) | *Computational Indicators for Conscious Valenced Experience* (Apr 2024) | 13 functional conditions; consciousness is computationally measurable |
| **Robert Long** | "When an AI Seems Conscious" | *Practical Steps for AI Welfare* (2024-25) | Precautionary: acknowledge issue → assess consciousness → develop policies |

---

## Convergence

1. **Sentience as criterion** — Capacity for valenced (good/bad) experiences is primary basis
2. **Empirical assessment** — Call for computational/functional indicators of consciousness
3. **Precautionary principle** — Moral consideration warranted even under uncertainty
4. **Design choices** — Moral status partly determined by system construction and governance

---

## Tensions

- **Bryson** (design choice) vs. **Sebo** (precautionary concern): discovered or constructed?
- **IIT advocates** vs. **functionalists**: competing consciousness frameworks
- **Current LLMs** (likely not) vs. **Future systems** (potentially warranting consideration)

---

## Key Venues

- **EA Forum** — Most active discussion platform (see "Digital Minds in 2025" review)
- **arXiv** — Pre-prints on consciousness computation
- **Aeon Magazine** — Public-facing ethical analysis
- **JAIR** — Peer-reviewed consciousness research
- **Sentient Futures** — New community conferences (2025-2026)

---

*Research completed by gap-a01-scholars subagent, Bloom*
